{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy.random as random\n",
    "from numpy.linalg import pinv\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Implement a fixed network to solve the XOR operation, where the total number of neurons is 3 and the number of layers is 2. Use the batch gradient descent for the optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Layer(object):\n",
    "    \"\"\"\n",
    "    Layer contains an array of neurons\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, *args):\n",
    "        self.weights = args[0]\n",
    "        self.bias = args[1]\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        \"\"\" x: input neurons\"\"\"\n",
    "        z = self.basis_function(self.weights, self.bias, x)\n",
    "        a = self.activation_function(self.sigmoid, z)\n",
    "        return (z, a)\n",
    "        \n",
    "    def basis_function(self, w, b, x):\n",
    "        z = w.dot(x) + b\n",
    "        return z\n",
    "    \n",
    "    def sigmoid(self, a):\n",
    "        return 1 / (1 + np.exp(-a))\n",
    "    \n",
    "    def activation_function(self, fun, z):\n",
    "        return fun(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Network(object):\n",
    "    \"\"\"A Network contains a list of layers, and functions to do feedforward and backpropagation\"\"\"\n",
    "    \n",
    "    def __init__(self, *args):\n",
    "        self.layers = []\n",
    "        \n",
    "        \"\"\"\n",
    "        a list of number of neurons in each layer\n",
    "        i.e. [2, 2, 1] means that there are 2 neurons in the input layer and 2 in the first and 1 in the second layer\n",
    "        \"\"\"\n",
    "        self.neuron_nums = args[0]\n",
    "        # x: features to be trained\n",
    "        self.x = args[1]\n",
    "        # N: number of training data\n",
    "        self.trg_data = args[2]\n",
    "        self.N = len(trg_data)\n",
    "        \n",
    "    def initialize_layers(neuron_nums, N):\n",
    "        for i in range(len(neuron_nums)):\n",
    "            self.initialize_layer(N, neuron_nums[i], neuron_nums[i+1])\n",
    "    \n",
    "    def initialize_layer(N, prev, curr, mu=0):\n",
    "        \"\"\" \n",
    "        Initializes weights and bias for current layer\n",
    "        N: number of training data\n",
    "        prev: number of neurons in previous layer\n",
    "        curr: number of neurons in current layer\n",
    "\n",
    "        mu = 0\n",
    "        sigma = 1 / sqrt(N) in order to avoid network saturation\n",
    "        \"\"\"\n",
    "        mu = 0\n",
    "        sigma = 1 / np.sqrt(N)\n",
    "\n",
    "        W = np.zeros((curr, prev))\n",
    "        b = np.zeros((curr, 1))\n",
    "        for c in range(curr):\n",
    "            b[c] = random.normal(mu, sigma)\n",
    "            for p in range(prev):\n",
    "                W[c][p] = random.normal(mu, sigma)\n",
    "\n",
    "        layer = Layer(W, b)\n",
    "        self.layers.append(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.7825954]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "N = 4\n",
    "layer1 = initialize_layer(N, 2, 2) # 2 input neurons from input layer, 2 current neurons\n",
    "layer2 = initialize_layer(N, 2, 1) # 2 input neurons from layer 1, 1 current neuron\n",
    "\n",
    "layers = []\n",
    "layers.append(layer1)\n",
    "layers.append(layer2)\n",
    "x = np.zeros((2, 1)) # x1 = 0, x2 = 0\n",
    "\n",
    "def feed_forward(N, x, layer1, layer2):\n",
    "    z1, a1 = layer1(x)\n",
    "    z2, a2 = layer2(a1)\n",
    "    return z1, a1, z2, a2\n",
    "\n",
    "z1, a1, z2, a2 = feed_forward(N)\n",
    "a2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
